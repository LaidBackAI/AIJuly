# 08-2 | 합성곱 신경망을 사용한 이미지 분류

```python
from tensorflow import keras
from sklearn.model_selection import train_test_split
(train_input, train_target), (test_input, test_target) =\
keras.datasets.fashion_mnist.load_data()
train_scaled = train_input.reshape(-1, 28, 28, 1) / 255.0
train_scaled, val_scaled, train_target, val_target = train_test_split(
    train_scaled, train_target, test_size=0.2, random_state=42)

model = keras.Sequential()
model.add(keras.layers.Conv2D(32, kernel_size=3, activation='relu',
                              padding='same', input_shape=(28,28,1)))

model.add(keras.layers.MaxPooling2D(2))

model.add(keras.layers.Conv2D(64, kernel_size=3, activation='relu',
                              padding='same'))
model.add(keras.layers.MaxPooling2D(2))

model.add(keras.layers.Flatten())
model.add(keras.layers.Dense(100, activation='relu'))
model.add(keras.layers.Dropout(0.4))
model.add(keras.layers.Dense(10, activation='softmax'))

model.summary()

keras.utils.plot_model(model)
```

![Untitled](https://user-images.githubusercontent.com/87055471/129478651-5a3cced3-3339-43e7-9ffa-3599fed95d1c.png)


```python
keras.utils.plot_model(model, show_shapes=True,
                       to_file='cnn-architecture.png', dpi=300)
```

![Untitled 1](https://user-images.githubusercontent.com/87055471/129478654-3b91231a-9063-416c-9fff-c69e298dd68b.png)


```python
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy',
              metrics='accuracy')
checkpoint_cb = keras.callbacks.ModelCheckpoint('best-cnn-model.h5')
early_stopping_cb = keras.callbacks.EarlyStopping(patience=2,
                                                  restore_best_weights=True)
history = model.fit(train_scaled, train_target, epochs=20,
                    validation_data=(val_scaled, val_target),
                    callbacks=[checkpoint_cb, early_stopping_cb])

import matplotlib.pyplot as plt
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.xlabel('epoch')
plt.ylabel('loss')
plt.legend(['train', 'val'])
plt.show()
```

![Untitled 2](https://user-images.githubusercontent.com/87055471/129478663-91d515e9-65af-4bcc-910f-66be6e16e0ee.png)


```python
model.evaluate(val_scaled, val_target)

plt.imshow(val_scaled[0].reshape(28, 28), cmap='gray_r')
plt.show()
```

![Untitled 3](https://user-images.githubusercontent.com/87055471/129478669-4cfd1322-6b0d-42ca-aee8-da0a28b66e2c.png)


```python
preds = model.predict(val_scaled[0:1])

plt.bar(range(1, 11), preds[0])
plt.xlabel('class')
plt.ylabel('prob.')
plt.show()
```

![Untitled 4](https://user-images.githubusercontent.com/87055471/129478672-d8575383-d924-4ba4-918a-0de91a0423a1.png)


```python
classes = ['티셔츠', '바지', '스웨터', '드레스', '코트', '샌달', '셔츠', '스니커즈',
           '가방', '앵클 부츠']

import numpy as np

test_scaled = test_input.reshape(-1, 28, 28, 1) / 255.0

model.evaluate(test_scaled, test_target)
```

합성곱 신경망의 주요 개념을 토대로 케라스 API를 사용해 합성곱 신경망을 만들어 보았다. 케라스의 Conv2D 클래스를 사용해 32개의 필터와 64개의 필터를 둔 2개의 합성곱 층을 추가했다. 두 합성곱 층 다음에는 모두 (2, 2) 크기의 최대 풀링 층을 배치했다. 두 번째 풀링 층을 통과한 특성 맵을 펼친 다음 밀집 은닉층에 연결하고 최종적으로 10개의 뉴런을 가진 출력층에서 샘플에 대한 확률을 출력했다.

조기 종료 기법을 사용해 모델을 훈련한 다음 검증 세트로 최적의 에포크에서 성능을 평가했다. 또 샘플 데이터 하나를 선택해 예측 클래스를 출력하는 방법을 살펴보았다.

마지막으로 이제까지 사용하지 않았던 테스트 세트를 사용해 최종 모델의 일반화 성능을 평가하였다. 항상 테스트 세트는 모델을 출시하기 직전 딱 한 번만 사용해야 한다. 그렇지 않다면 모델을 실전에 투입했을 때 성능을 올바르게 예측하지 못한다.

합성곱 신경망은 이미지를 주로 다루기 때문에 각 층의 출력을 시각화하기 좋다.

- 텐서플로의 **Conv2D, MaxPooling2D, plot_model**를 활용한 실습을 했다.
